# ğŸš€ Multilingual Insurance RAG System (Quark Hackathon 2025)

## ğŸ‘¨â€ğŸ’» Authors
- **Amogh Malagi, Naitik Verma, Ronan Coutinho, Vidit Jain**
- ğŸ“… Date: **3/10/2025**

Link to the video demonstration: https://drive.google.com/file/d/16SrpiJPXX3bQUblUBrAciyV9_DHkQmAg/view?usp=drivesdk

## ğŸ“ Introduction
This project presents a fully **open-source**, **cloud-agnostic** multilingual **Retrieval-Augmented Generation (RAG)** system for **insurance documentation**. Designed to support **multiple Indian languages**, the system enables both **text and voice-based interactions** while ensuring **privacy-friendly, cost-effective deployment** without reliance on proprietary cloud platforms.

By integrating **open-source LLMs (LLaMA)** and leveraging **FastAPI, FastText, Deep Translate**, the system delivers **context-aware responses with enhanced accuracy**.

This chatbot not only facilitates **real-time translation** and **multilingual conversations**, but also supports essential **transactional services** such as **policy inquiries** and **service requests**, making it a practical and scalable solution for the insurance sector. ğŸ¦ğŸ’¬

### ğŸŒŸ Key Features
- ğŸŒ **Multilingual support** for **9 Indian languages**
- ğŸ™ï¸ **Voice and text input processing**
- ğŸ“„ **PDF document processing** and embedding generation
- ğŸ§  **Context-aware responses using RAG**
- ğŸ”„ **Real-time translation**

### ğŸ› ï¸ Tech Stack
- ğŸš€ **FastAPI** for backend
- ğŸ·ï¸ **FastText** for embeddings
- ğŸŒ **Deep Translate** for language translation
- ğŸ¦™ **LLaMA 3.1 (via Ollama)** for response generation
- âš›ï¸ **React** for frontend

## âš™ï¸ Installation & Setup

### ğŸ“Œ Prerequisites
- ğŸ **Python 3.13+**
- ğŸ“‚ **FastText pre-trained model (cc.en.300.bin)**
- ğŸ’» **Node.js and npm for frontend**
- ğŸ¦™ **Ollama installed and running**

### ğŸ“¥ Installation Steps
1ï¸âƒ£ Clone the repository:
```bash
git clone https://github.com/ViditJain123/quarkhackathon25.git
cd quarkhackathon25
```

2ï¸âƒ£ Create and activate virtual environment:
```bash
python -m venv rag_env
source rag_env/bin/activate  # On Windows: rag_env\Scripts\activate
```

3ï¸âƒ£ Install dependencies:
```bash
cd backend
pip install -r requirements
```

## ğŸš€ Usage Guide

### ğŸ¦™ Running the Ollama server (open-source LLM)
ğŸ“¥ Download Ollama from [Ollama Official Site](https://ollama.com/download)

Run the following commands in terminal:
```bash
ollama serve
ollama run llama3.1
```
To stop the server:
```bash
ollama stop llama3.1
```

### ğŸ¦™ Downloading the embeddings model (Fasttext by Facebook Research)
Run the following commands in terminal in the backend/app/models folder:
```bash
wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz
gunzip cc.en.300.bin.gz
```


### â–¶ï¸ Running the Project (after creating your environment)

1ï¸âƒ£ Start the FastAPI server:
```bash
cd backend
uvicorn app.main:app --reload
```

2ï¸âƒ£ Start the frontend server:
```bash
cd frontend
npm i
npm run dev
```

## ğŸ›ï¸ Architecture Overview

### ğŸ“‚ Directory Structure
```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ schemas.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ embedding_service.py
â”‚   â”‚   â”œâ”€â”€ translation_service.py
â”‚   â”‚   â”œâ”€â”€ rag_service.py
â”‚   â”‚   â”œâ”€â”€ llm_service.py
â”‚   â”‚   â””â”€â”€ speech_service.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ helpers.py
â”œâ”€â”€ embeddings_output/
â””â”€â”€ models/
```

### ğŸ”‘ Core Components
ğŸ“„ **Embedding Service** : Processes PDFs and generates FastText embeddings  
ğŸ” **RAG Service** : Handles context retrieval and query processing  
ğŸŒ **Translation Service** : Manages language detection and translation  
ğŸ¤ **Speech Service** : Handles voice input/output processing  
ğŸ§  **LLM Service** : Interfaces with LLaMA for response generation  

## ğŸ“¡ API Documentation

### ğŸ”Œ Endpoints

#### ğŸ“¤ `POST /api/upload`
Handles **voice input processing** ğŸ¤
```json
Request:
- FormData with 'file' field (audio/mpeg)

Response:
{
    "audio_content": bytes,
    "detected_language": string
}
```

#### ğŸ’¬ `POST /api/query`
Handles **text input processing** ğŸ“
```json
Request:
{
    "prompt": string
}

Response:
{
    "response": string,
    "detected_language": string
}
```

### ğŸ“š References
- ğŸ“˜ [FastAPI Documentation](https://fastapi.tiangolo.com/)
- ğŸ“— [FastText Documentation](https://fasttext.cc/)
- ğŸ¦™ [LLaMA Documentation](https://github.com/facebookresearch/llama)
